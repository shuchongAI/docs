---
title: "Claude Messages API"
description: "
- Fully compatible with Claude Messages API format

- Supports multi-turn conversations and single queries

- Supports multimodal content including text and images
"
api: "POST https://api.apimart.ai/v1/messages"
---

<RequestExample>

```bash cURL
curl https://api.apimart.ai/v1/messages \
  -H "x-api-key: $API_KEY" \
  -H "anthropic-version: 2025-10-01" \
  -H "content-type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5-20250929",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "Hello, world"}
    ]
  }'
```

```python Python
import anthropic

client = anthropic.Anthropic(
    api_key="YOUR_API_KEY",
    base_url="https://api.apimart.ai"
)

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Hello, world"}
    ]
)

print(message.content)
```

```javascript JavaScript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: process.env.API_KEY,
  baseURL: 'https://api.apimart.ai'
});

const message = await client.messages.create({
  model: 'claude-sonnet-4-5-20250929',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'Hello, world' }
  ]
});

console.log(message.content);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io/ioutil"
    "net/http"
    "os"
)

func main() {
    url := "https://api.apimart.ai/v1/messages"

    payload := map[string]interface{}{
        "model": "claude-sonnet-4-5-20250929",
        "max_tokens": 1024,
        "messages": []map[string]string{
            {
                "role":    "user",
                "content": "Hello, world",
            },
        },
    }

    jsonData, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    req.Header.Set("x-api-key", os.Getenv("API_KEY"))
    req.Header.Set("anthropic-version", "2025-10-01")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        panic(err)
    }
    defer resp.Body.Close()

    body, _ := ioutil.ReadAll(resp.Body)
    fmt.Println(string(body))
}
```

```java Java
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.net.URI;

public class Main {
    public static void main(String[] args) throws Exception {
        String url = "https://api.apimart.ai/v1/messages";
        String apiKey = System.getenv("API_KEY");

        String payload = """
        {
          "model": "claude-sonnet-4-5-20250929",
          "max_tokens": 1024,
          "messages": [
            {
              "role": "user",
              "content": "Hello, world"
            }
          ]
        }
        """;

        HttpClient client = HttpClient.newHttpClient();
        HttpRequest request = HttpRequest.newBuilder()
            .uri(URI.create(url))
            .header("x-api-key", apiKey)
            .header("anthropic-version", "2025-10-01")
            .header("Content-Type", "application/json")
            .POST(HttpRequest.BodyPublishers.ofString(payload))
            .build();

        HttpResponse<String> response = client.send(request,
            HttpResponse.BodyHandlers.ofString());

        System.out.println(response.body());
    }
}
```

```php PHP
<?php

$url = "https://api.apimart.ai/v1/messages";
$apiKey = getenv('API_KEY');

$payload = [
    "model" => "claude-sonnet-4-5-20250929",
    "max_tokens" => 1024,
    "messages" => [
        [
            "role" => "user",
            "content" => "Hello, world"
        ]
    ]
];

$ch = curl_init($url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch, CURLOPT_POST, true);
curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($payload));
curl_setopt($ch, CURLOPT_HTTPHEADER, [
    "x-api-key: " . $apiKey,
    "anthropic-version: 2025-10-01",
    "Content-Type: application/json"
]);

$response = curl_exec($ch);
curl_close($ch);

echo $response;
?>
```

```ruby Ruby
require 'net/http'
require 'json'
require 'uri'

url = URI("https://api.apimart.ai/v1/messages")
api_key = ENV['API_KEY']

payload = {
  model: "claude-sonnet-4-5-20250929",
  max_tokens: 1024,
  messages: [
    {
      role: "user",
      content: "Hello, world"
    }
  ]
}

http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true

request = Net::HTTP::Post.new(url)
request["x-api-key"] = api_key
request["anthropic-version"] = "2025-10-01"
request["Content-Type"] = "application/json"
request.body = payload.to_json

response = http.request(request)
puts response.body
```

```swift Swift
import Foundation

let url = URL(string: "https://api.apimart.ai/v1/messages")!
let apiKey = ProcessInfo.processInfo.environment["API_KEY"] ?? ""

let payload: [String: Any] = [
    "model": "claude-sonnet-4-5-20250929",
    "max_tokens": 1024,
    "messages": [
        [
            "role": "user",
            "content": "Hello, world"
        ]
    ]
]

var request = URLRequest(url: url)
request.httpMethod = "POST"
request.setValue(apiKey, forHTTPHeaderField: "x-api-key")
request.setValue("2025-10-01", forHTTPHeaderField: "anthropic-version")
request.setValue("application/json", forHTTPHeaderField: "Content-Type")
request.httpBody = try? JSONSerialization.data(withJSONObject: payload)

let task = URLSession.shared.dataTask(with: request) { data, response, error in
    if let error = error {
        print("Error: \(error)")
        return
    }
    
    if let data = data, let responseString = String(data: data, encoding: .utf8) {
        print(responseString)
    }
}

task.resume()
```

```csharp C#
using System;
using System.Net.Http;
using System.Text;
using System.Threading.Tasks;

class Program
{
    static async Task Main(string[] args)
    {
        var url = "https://api.apimart.ai/v1/messages";
        var apiKey = Environment.GetEnvironmentVariable("API_KEY");

        var payload = @"{
            ""model"": ""claude-sonnet-4-5-20250929"",
            ""max_tokens"": 1024,
            ""messages"": [
                {
                    ""role"": ""user"",
                    ""content"": ""Hello, world""
                }
            ]
        }";

        using var client = new HttpClient();
        client.DefaultRequestHeaders.Add("x-api-key", apiKey);
        client.DefaultRequestHeaders.Add("anthropic-version", "2025-10-01");

        var content = new StringContent(payload, Encoding.UTF8, "application/json");
        var response = await client.PostAsync(url, content);
        var result = await response.Content.ReadAsStringAsync();

        Console.WriteLine(result);
    }
}
```

```c C
#include <stdio.h>
#include <curl/curl.h>
#include <stdlib.h>

int main(void) {
    CURL *curl;
    CURLcode res;
    const char *api_key = getenv("API_KEY");

    curl_global_init(CURL_GLOBAL_DEFAULT);
    curl = curl_easy_init();

    if(curl) {
        const char *url = "https://api.apimart.ai/v1/messages";
        const char *payload = "{"
            "\"model\":\"claude-sonnet-4-5-20250929\","
            "\"max_tokens\":1024,"
            "\"messages\":[{\"role\":\"user\",\"content\":\"Hello, world\"}]"
        "}";

        char auth_header[256];
        snprintf(auth_header, sizeof(auth_header), "x-api-key: %s", api_key);

        struct curl_slist *headers = NULL;
        headers = curl_slist_append(headers, auth_header);
        headers = curl_slist_append(headers, "anthropic-version: 2025-10-01");
        headers = curl_slist_append(headers, "Content-Type: application/json");

        curl_easy_setopt(curl, CURLOPT_URL, url);
        curl_easy_setopt(curl, CURLOPT_POSTFIELDS, payload);
        curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);

        res = curl_easy_perform(curl);

        if(res != CURLE_OK) {
            fprintf(stderr, "curl_easy_perform() failed: %s\n",
                    curl_easy_strerror(res));
        }

        curl_slist_free_all(headers);
        curl_easy_cleanup(curl);
    }

    curl_global_cleanup();
    return 0;
}
```

```objectivec Objective-C
#import <Foundation/Foundation.h>

int main(int argc, const char * argv[]) {
    @autoreleasepool {
        NSURL *url = [NSURL URLWithString:@"https://api.apimart.ai/v1/messages"];
        NSString *apiKey = [NSProcessInfo processInfo].environment[@"API_KEY"];
        
        NSDictionary *payload = @{
            @"model": @"claude-sonnet-4-5-20250929",
            @"max_tokens": @1024,
            @"messages": @[
                @{
                    @"role": @"user",
                    @"content": @"Hello, world"
                }
            ]
        };
        
        NSError *error;
        NSData *jsonData = [NSJSONSerialization dataWithJSONObject:payload
                                                          options:0
                                                            error:&error];
        
        NSMutableURLRequest *request = [NSMutableURLRequest requestWithURL:url];
        [request setHTTPMethod:@"POST"];
        [request setValue:apiKey forHTTPHeaderField:@"x-api-key"];
        [request setValue:@"2025-10-01" forHTTPHeaderField:@"anthropic-version"];
        [request setValue:@"application/json" forHTTPHeaderField:@"Content-Type"];
        [request setHTTPBody:jsonData];
        
        NSURLSessionDataTask *task = [[NSURLSession sharedSession] 
            dataTaskWithRequest:request
            completionHandler:^(NSData *data, NSURLResponse *response, NSError *error) {
                if (error) {
                    NSLog(@"Error: %@", error);
                    return;
                }
                NSString *result = [[NSString alloc] initWithData:data 
                                                        encoding:NSUTF8StringEncoding];
                NSLog(@"%@", result);
            }];
        
        [task resume];
        [[NSRunLoop mainRunLoop] run];
    }
    return 0;
}
```

```ocaml OCaml
(* Requires cohttp and yojson libraries *)
open Lwt
open Cohttp
open Cohttp_lwt_unix

let url = "https://api.apimart.ai/v1/messages"
let api_key = Sys.getenv "API_KEY"

let payload = {|{
  "model": "claude-sonnet-4-5-20250929",
  "max_tokens": 1024,
  "messages": [
    {
      "role": "user",
      "content": "Hello, world"
    }
  ]
}|}

let () =
  let headers = Header.init ()
    |> fun h -> Header.add h "x-api-key" api_key
    |> fun h -> Header.add h "anthropic-version" "2025-10-01"
    |> fun h -> Header.add h "Content-Type" "application/json"
  in
  let body = Cohttp_lwt.Body.of_string payload in
  
  let response = Client.post ~headers ~body (Uri.of_string url) >>= fun (resp, body) ->
    body |> Cohttp_lwt.Body.to_string >|= fun body_str ->
    print_endline body_str
  in
  Lwt_main.run response
```

```dart Dart
import 'dart:convert';
import 'dart:io';
import 'package:http/http.dart' as http;

void main() async {
  final url = Uri.parse('https://api.apimart.ai/v1/messages');
  final apiKey = Platform.environment['API_KEY'];
  
  final payload = {
    'model': 'claude-sonnet-4-5-20250929',
    'max_tokens': 1024,
    'messages': [
      {
        'role': 'user',
        'content': 'Hello, world'
      }
    ]
  };
  
  final response = await http.post(
    url,
    headers: {
      'x-api-key': apiKey!,
      'anthropic-version': '2025-10-01',
      'Content-Type': 'application/json',
    },
    body: jsonEncode(payload),
  );
  
  print(response.body);
}
```

```r R
library(httr)
library(jsonlite)

url <- "https://api.apimart.ai/v1/messages"
api_key <- Sys.getenv("API_KEY")

payload <- list(
  model = "claude-sonnet-4-5-20250929",
  max_tokens = 1024,
  messages = list(
    list(
      role = "user",
      content = "Hello, world"
    )
  )
)

response <- POST(
  url,
  add_headers(
    `x-api-key` = api_key,
    `anthropic-version` = "2025-10-01",
    `Content-Type` = "application/json"
  ),
  body = toJSON(payload, auto_unbox = TRUE),
  encode = "raw"
)

cat(content(response, "text"))
```

</RequestExample>

<ResponseExample>

```json 200
{
  "code": 200,
  "data": {
    "id": "msg_013Zva2CMHLNnXjNJJKqJ2EF",
    "type": "message",
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "Hello! I'm Claude. Nice to meet you."
      }
    ],
    "model": "claude-sonnet-4-5-20250929",
    "stop_reason": "end_turn",
    "stop_sequence": null,
    "usage": {
      "input_tokens": 12,
      "output_tokens": 18
    }
  }
}
```

```json 400
{
  "type": "error",
  "error": {
    "type": "invalid_request_error",
    "message": "Invalid request parameters"
  }
}
```

```json 401
{
  "type": "error",
  "error": {
    "type": "authentication_error",
    "message": "Invalid API key"
  }
}
```

```json 429
{
  "type": "error",
  "error": {
    "type": "rate_limit_error",
    "message": "Rate limit exceeded"
  }
}
```

```json 500
{
  "type": "error",
  "error": {
    "type": "api_error",
    "message": "Internal server error"
  }
}
```

</ResponseExample>

## Authorizations

<ParamField header="x-api-key" type="string" required>
  API key for authentication

  Visit the [API Key Management Page](https://api.apimart.ai/console/token) to get your API Key

  Add to request header:
  ```
  x-api-key: YOUR_API_KEY
  ```
</ParamField>

<ParamField header="anthropic-version" type="string" required>
  API version

  Specifies the Claude API version to use

  Example: `2025-10-01`
</ParamField>

## Body

<ParamField body="model" type="string" required default="claude-haiku-4-5-20251001">
  Model name

  - `claude-haiku-4-5-20251001` - Claude 4.5 Fast Response Version
  - `claude-sonnet-4-5-20250929` - Claude 4.5 Balanced Version
  - `claude-opus-4-1-20250805` - Most Capable Claude 4.1 Flagship Model
  - `claude-opus-4-1-20250805-thinking` - Claude 4.1 Opus Deep Thinking Version
  - `claude-sonnet-4-5-20250929-thinking` - Claude 4.5 Sonnet Deep Thinking Version
</ParamField>

<ParamField body="messages" type="array" required>
  List of messages

  Array of messages for the model to generate the next response. Each message contains `role` and `content` fields.

  **ðŸ’¡ Quick fill (Try it area):**
  1. Click "+ Add an item" to add a message
  2. `role` input: `user` (user message) or `assistant` (AI response, for multi-turn)
  3. `content` input: your message text
  
  <Expandable title="Field details">
    <ParamField body="role" type="string" required default="user">
      Role type
      
      Options: `user` (user message), `assistant` (AI response, for multi-turn conversations and prefilling)
      
      Note: Claude API uses a separate `system` parameter for system prompts, not in messages
    </ParamField>

    <ParamField body="content" type="string" required>
      Message content
      
      Text content of the message
    </ParamField>
  </Expandable>

  **Single user message:**
  ```json
  [{"role": "user", "content": "Hello, Claude"}]
  ```

  **Multi-turn conversation:**
  ```json
  [
    {"role": "user", "content": "Hello there."},
    {"role": "assistant", "content": "Hi, I'm Claude. How can I help you?"},
    {"role": "user", "content": "Can you explain LLMs in plain English?"}
  ]
  ```

  **Prefilled assistant response:**
  ```json
  [
    {"role": "user", "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"},
    {"role": "assistant", "content": "The best answer is ("}
  ]
  ```
</ParamField>

<ParamField body="max_tokens" type="integer">
  Maximum tokens to generate

  Maximum number of tokens to generate before stopping. The model may stop before reaching this limit.

  Different models have different maximum values. Minimum: 1
</ParamField>

<ParamField body="system" type="string | array">
  System prompt

  System prompts set Claude's role, personality, goals, and instructions.

  **String format:**
  ```json
  {
    "system": "You are a professional Python programming tutor"
  }
  ```

  **Structured format:**
  ```json
  {
    "system": [
      {
        "type": "text",
        "text": "You are a professional Python programming tutor"
      }
    ]
  }
  ```
</ParamField>

<ParamField body="temperature" type="number">
  Temperature parameter, range 0-1

  Controls randomness of output:
  - Low values (e.g., 0.2): More deterministic, conservative
  - High values (e.g., 0.8): More random, creative

  Default: 1.0
</ParamField>

<ParamField body="top_p" type="number">
  Nucleus sampling parameter, range 0-1

  Uses nucleus sampling. Recommend using either `temperature` or `top_p`, not both.

  Default: 1.0
</ParamField>

<ParamField body="top_k" type="integer">
  Top-K sampling

  Sample from top K options only, removes "long tail" low probability responses.

  Recommended for advanced use cases only.
</ParamField>

<ParamField body="stream" type="boolean">
  Enable streaming

  When `true`, uses Server-Sent Events (SSE) to stream responses.

  Default: false
</ParamField>

<ParamField body="stop_sequences" type="array">
  Stop sequences

  Custom text sequences that cause the model to stop generating.

  Maximum 4 sequences.

  Example: `["\n\nHuman:", "\n\nAssistant:"]`
</ParamField>

<ParamField body="metadata" type="object">
  Metadata

  Metadata object for the request.

  Includes:
  - `user_id`: User identifier
</ParamField>

<ParamField body="tools" type="array">
  Tool definitions

  List of tools the model can use to complete tasks.

  **Function tool example:**
  ```json
  {
    "tools": [
      {
        "name": "get_weather",
        "description": "Get the current weather in a given location",
        "input_schema": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"],
              "description": "Temperature unit"
            }
          },
          "required": ["location"]
        }
      }
    ]
  }
  ```

  Supported tool types:
  - Custom function tools
  - Computer use tool (computer_20241022)
  - Text editor tool (text_editor_20241022)
  - Bash tool (bash_20241022)
</ParamField>

<ParamField body="tool_choice" type="object">
  Tool choice strategy

  Controls how the model uses tools:

  - `{"type": "auto"}`: Auto-decide (default)
  - `{"type": "any"}`: Must use a tool
  - `{"type": "tool", "name": "tool_name"}`: Use specific tool
</ParamField>

## Response

<ResponseField name="id" type="string">
  Unique message identifier

  Example: `"msg_013Zva2CMHLNnXjNJJKqJ2EF"`
</ResponseField>

<ResponseField name="type" type="string">
  Object type

  Always `"message"`
</ResponseField>

<ResponseField name="role" type="string">
  Role

  Always `"assistant"`
</ResponseField>

<ResponseField name="content" type="array">
  Content blocks array

  Content generated by the model, as an array of content blocks.

  **Text content:**
  ```json
  [{"type": "text", "text": "Hello! I'm Claude."}]
  ```

  **Tool use:**
  ```json
  [
    {
      "type": "tool_use",
      "id": "toolu_01A09q90qw90lq917835lq9",
      "name": "get_weather",
      "input": {"location": "San Francisco, CA", "unit": "celsius"}
    }
  ]
  ```

  Content types:
  - `text`: Text content
  - `tool_use`: Tool invocation
</ResponseField>

<ResponseField name="model" type="string">
  Model that handled the request

  Example: `"claude-sonnet-4-5-20250929"`
</ResponseField>

<ResponseField name="stop_reason" type="string">
  Stop reason

  Possible values:
  - `end_turn`: Natural completion
  - `max_tokens`: Reached maximum tokens
  - `stop_sequence`: Hit stop sequence
  - `tool_use`: Invoked a tool
</ResponseField>

<ResponseField name="stop_sequence" type="string | null">
  Stop sequence triggered

  The stop sequence that was generated, if any; otherwise `null`
</ResponseField>

<ResponseField name="usage" type="object">
  Token usage statistics

  <Expandable title="Properties">
    <ResponseField name="input_tokens" type="integer">
      Number of input tokens
    </ResponseField>

    <ResponseField name="output_tokens" type="integer">
      Number of output tokens
    </ResponseField>
  </Expandable>
</ResponseField>

## Usage Examples

### Basic Conversation

```python
import anthropic

client = anthropic.Anthropic(
    api_key="YOUR_API_KEY",
    base_url="https://api.apimart.ai"
)

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Explain quantum computing basics"}
    ]
)

print(message.content[0].text)
```

### Multi-turn Conversation

```python
messages = [
    {"role": "user", "content": "What is machine learning?"},
    {"role": "assistant", "content": "Machine learning is a branch of AI..."},
    {"role": "user", "content": "Can you give a practical example?"}
]

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=messages
)
```

### Using System Prompts

```python
message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    system="You are a senior Python developer expert in code review and optimization.",
    messages=[
        {"role": "user", "content": "How to optimize this code?\n\n[code]"}
    ]
)
```

### Streaming Response

```python
with client.messages.stream(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Write a short essay about AI"}
    ]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

### Tool Use

```python
tools = [
    {
        "name": "get_stock_price",
        "description": "Get real-time stock price",
        "input_schema": {
            "type": "object",
            "properties": {
                "ticker": {
                    "type": "string",
                    "description": "Stock ticker symbol, e.g., AAPL"
                }
            },
            "required": ["ticker"]
        }
    }
]

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    tools=tools,
    messages=[
        {"role": "user", "content": "What's Tesla's stock price?"}
    ]
)

# Handle tool calls
if message.stop_reason == "tool_use":
    tool_use = next(block for block in message.content if block.type == "tool_use")
    print(f"Calling tool: {tool_use.name}")
    print(f"Arguments: {tool_use.input}")
```

### Vision Understanding

```python
message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "url",
                        "url": "https://example.com/image.jpg"
                    }
                },
                {
                    "type": "text",
                    "text": "Describe this image"
                }
            ]
        }
    ]
)
```

### Base64 Image

```python
import base64

with open("image.jpg", "rb") as image_file:
    image_data = base64.b64encode(image_file.read()).decode("utf-8")

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/jpeg",
                        "data": image_data
                    }
                },
                {
                    "type": "text",
                    "text": "Analyze this image"
                }
            ]
        }
    ]
)
```

## Best Practices

### 1. Prompt Engineering

**Clear role definition:**
```python
system = """You are an experienced data scientist specializing in:
- Statistical analysis and data visualization
- Machine learning model development
- Python and R programming
Provide professional, accurate advice."""
```

**Structured output:**
```python
message = "Please return the analysis results in JSON format with summary, key_findings, and recommendations fields."
```

### 2. Error Handling

```python
from anthropic import APIError, RateLimitError

try:
    message = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Hello"}]
    )
except RateLimitError:
    print("Rate limit exceeded, please retry later")
except APIError as e:
    print(f"API error: {e}")
```

### 3. Token Optimization

```python
# Use shorter prompts
messages = [
    {"role": "user", "content": "Summarize key points:\n\n[long text]"}
]

# Limit output length
message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=500,  # Limit output
    messages=messages
)
```

### 4. Prefilling Responses

```python
# Guide model to specific format
messages = [
    {"role": "user", "content": "List 5 Python best practices"},
    {"role": "assistant", "content": "Here are 5 Python best practices:\n\n1."}
]

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=messages
)
```

## Streaming Response Handling

### Python Streaming

```python
import anthropic

client = anthropic.Anthropic(
    api_key="YOUR_API_KEY",
    base_url="https://api.apimart.ai"
)

with client.messages.stream(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Write a Python decorator example"}
    ]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

### JavaScript Streaming

```javascript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: process.env.API_KEY,
  baseURL: 'https://api.apimart.ai'
});

const stream = await client.messages.stream({
  model: 'claude-sonnet-4-5-20250929',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'Write a React component example' }
  ]
});

for await (const chunk of stream) {
  if (chunk.type === 'content_block_delta' && 
      chunk.delta.type === 'text_delta') {
    process.stdout.write(chunk.delta.text);
  }
}
```

## Important Notes

1. **API Key Security**:
   - Store API keys in environment variables
   - Never hardcode keys in source code
   - Rotate keys regularly

2. **Rate Limiting**:
   - Be aware of API rate limits
   - Implement retry mechanisms
   - Use exponential backoff

3. **Token Management**:
   - Monitor token usage
   - Optimize prompt length
   - Use appropriate max_tokens values

4. **Model Selection**:
   - Opus: Complex tasks, deep thinking required
   - Sonnet: Balanced performance and cost
   - Haiku: Fast response, simple tasks

5. **Content Filtering**:
   - Validate user input
   - Filter sensitive information
   - Implement content moderation

